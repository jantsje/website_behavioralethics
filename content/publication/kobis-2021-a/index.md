---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Artificial intelligence versus Maya Angelou: Experimental evidence that people
  cannot differentiate AI-generated from human-written poetry'
subtitle: ''
summary: ''
authors:
- Nils KÃ¶bis
- Luca D. Mossink
tags:
- Computational creativity
- Creativity
- Machine behavior
- Natural language generation
- Test
- Turing
categories: []
date: '2021-01-01'
lastmod: 2023-04-06T14:32:28+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-04-06T12:32:27.518983Z'
publication_types:
- '2'
abstract: The release of openly available, robust natural language generation algorithms
  (NLG) has spurred much public attention and debate. One reason lies in the algorithms'
  purported ability to generate humanlike text across various domains. Empirical evidence
  using incentivized tasks to assess whether people (a) can distinguish and (b) prefer
  algorithm-generated versus human-written text is lacking. We conducted two experiments
  assessing behavioral reactions to the state-of-the-art Natural Language Generation
  algorithm GPT-2 (Ntotal = 830). Using the identical starting lines of human poems,
  GPT-2 produced samples of poems. From these samples, either a random poem was chosen
  (Human-out-of-theloop) or the best one was selected (Human-in-the-loop) and in turn
  matched with a human-written poem. In a new incentivized version of the Turing Test,
  participants failed to reliably detect the algorithmicallygenerated poems in the
  Human-in-the-loop treatment, yet succeeded in the Human-out-of-the-loop treatment.
  Further, people reveal a slight aversion to algorithm-generated poetry, independent
  on whether participants were informed about the algorithmic origin of the poem (Transparency)
  or not (Opacity). We discuss what these results convey about the performance of
  NLG algorithms to produce human-like text and propose methodologies to study such
  learning algorithms in human-agent experimental settings.
publication: '*Computers in Human Behavior*'
doi: 10.1016/j.chb.2020.106553
links:
- name: URL
  url: https://linkinghub.elsevier.com/retrieve/pii/S0747563220303034
---
